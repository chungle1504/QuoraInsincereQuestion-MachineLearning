{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# BÁO CÁO BÀI TẬP LỚN\n **Học phần**: Machine Learning - INT3405_20\n \n **Giảng viên**: Trần Quốc Long\n \n **Sinh viên**: Lê Hữu Chung\n \n **MSSV**: 18020236\n ","metadata":{}},{"cell_type":"markdown","source":"## **Introduction**\n* Quora là một nền tảng cho phép mọi người học hỏi lẫn nhau. Trên Quora, mọi người đều có thể đặt câu hỏi và kết nối với những người khác, mong muốn được giao lưu với những người đóng góp thông tin chi tiết độc đáo và có câu trả lời chất lượng.\n* Hiện nay, xử lý những nội dung độc hại và gây chia rẽ là một thách thức đối với bất kỳ trang web nào.\n* Quora muốn giải quyết vấn đề này để giữ cho nền tảng của họ trở thành nơi mà người dùng có thể cảm thấy an toàn khi chia sẻ kiến thức với toàn cộng đồng.\n* Vậy mục tiêu, thách thức của dự án này là nhận diện được những câu hỏi \"insincere\" - những câu hỏi không mang tính chất đóng góp, thiếu chân thành, thậm chí để đả kích một cá nhân, tập thể hay tổ chức nào đó. Ngoài ra, những câu hỏi có ý định đưa ra một tuyên bố hơn là tìm kiếm những câu trả lời hữu ích cũng cần bị loại bỏ.\n","metadata":{}},{"cell_type":"markdown","source":"## **List of contents**\n1. Khởi tạo dự án\n2. Tiền xử lý dữ liệu\n3. Chuẩn bị mô hình\n4. Huấn luyện mô hình","metadata":{}},{"cell_type":"markdown","source":"# **1. Khởi tạo dự án**","metadata":{}},{"cell_type":"markdown","source":"## 1.a Import các thư viện cần thiết.","metadata":{"_uuid":"710ed17d0c57bd287be0ee3b2782a53a54510561"}},{"cell_type":"code","source":"import time\nimport random\nimport pandas as pd\nimport numpy as np\nimport gc\nimport re\nimport torch\nfrom torchtext import data\nimport spacy\nfrom tqdm import tqdm_notebook, tnrange\nfrom tqdm.auto import tqdm\n\ntqdm.pandas(desc='Progress')\nfrom collections import Counter\nfrom textblob import TextBlob\nfrom nltk import word_tokenize\n\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\nfrom torch.autograd import Variable\nfrom torchtext.data import Example\nfrom sklearn.metrics import f1_score\nimport torchtext\nimport os \n\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\n\n# cross validation and metrics\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import f1_score\nfrom torch.optim.optimizer import Optimizer\nfrom unidecode import unidecode","metadata":{"_uuid":"abb7e3c30b8a412a50c6b451c49939e3cf4bc11b","scrolled":true,"execution":{"iopub.status.busy":"2021-06-10T23:34:58.469949Z","iopub.execute_input":"2021-06-10T23:34:58.470239Z","iopub.status.idle":"2021-06-10T23:35:04.164699Z","shell.execute_reply.started":"2021-06-10T23:34:58.470183Z","shell.execute_reply":"2021-06-10T23:35:04.163962Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"Using TensorFlow backend.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 1.b Thiết lập các tham số cơ bản.","metadata":{"_uuid":"9a4ff5590a6f152dc1bec5aeca79aef10218f7de"}},{"cell_type":"code","source":"embed_size = 300 # how big is each word vector\nmax_features = 185777 # 120000 # how many unique words to use (i.e num rows in embedding vector)\nmaxlen = 70 # max number of words in a question to use\nbatch_size = 512 # how many samples to process at once\nn_epochs = 5 # how many times to iterate over all samples\nn_splits = 5 # Number of K-fold Splits\n\nSEED = 2021","metadata":{"_uuid":"deee49df5ca1c4413f71677939e26aa1ff784e44","scrolled":true,"execution":{"iopub.status.busy":"2021-06-10T23:35:04.167898Z","iopub.execute_input":"2021-06-10T23:35:04.168123Z","iopub.status.idle":"2021-06-10T23:35:04.174697Z","shell.execute_reply.started":"2021-06-10T23:35:04.168079Z","shell.execute_reply":"2021-06-10T23:35:04.173877Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## 1.c Đảm bảo tính xác định (determinism) \n\nVì ở phần sau, em dùng mô hình LSTM - train trên GPU nên sẽ thiếu tính \"determinism\" sau mỗi lần train. Có thể hiểu nôm na rằng sau 2 lần train với cùng một bộ dữ liệu, chúng ta sẽ có 2 mô hình không hoàn toàn giống nhau, một cái tốt hơn và một cái cho ra kết quả tệ hơn. Mặc dù sự sai khác của 2 mô hình này là không nhiều nhưng để ổn định hơn, em sẽ xử lý nó bằng cách sử dụng \"seed\". Seed là một điểm bắt đầu trong một chuỗi xác định, nó đảm bảo rằng khi ta dùng cùng một seed, kết quả cho ra qua các lần chạy đều giống nhau.\n\nTham khảo tại: https://www.kaggle.com/hengzheng/pytorch-starter. \n","metadata":{"_uuid":"654cbe3c8a1f2a618a2441afe00df3b4a89e0a58"}},{"cell_type":"code","source":"def seed_everything(seed=1029):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\nseed_everything()","metadata":{"_uuid":"58bbf87335799247586aaed16531f4d28d10ed4a","scrolled":true,"execution":{"iopub.status.busy":"2021-06-10T23:35:04.175807Z","iopub.execute_input":"2021-06-10T23:35:04.176088Z","iopub.status.idle":"2021-06-10T23:35:04.191295Z","shell.execute_reply.started":"2021-06-10T23:35:04.176026Z","shell.execute_reply":"2021-06-10T23:35:04.190516Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# **2. Tiền xử lý dữ liệu**","metadata":{}},{"cell_type":"markdown","source":"## 2.a Khảo sát dữ liệu","metadata":{}},{"cell_type":"markdown","source":"### 2.a.i Load dữ liệu từ cuộc thi","metadata":{}},{"cell_type":"code","source":"df_train = pd.read_csv(\"../input/train.csv\")\ndf_test = pd.read_csv(\"../input/test.csv\")\ndf = pd.concat([df_train ,df_test],sort=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T23:35:04.192990Z","iopub.execute_input":"2021-06-10T23:35:04.193949Z","iopub.status.idle":"2021-06-10T23:35:09.657783Z","shell.execute_reply.started":"2021-06-10T23:35:04.193411Z","shell.execute_reply":"2021-06-10T23:35:09.656894Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"### 2.a.ii Một cái nhìn sơ qua về dữ liệu","metadata":{}},{"cell_type":"code","source":"df_train.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-10T23:35:09.659114Z","iopub.execute_input":"2021-06-10T23:35:09.659376Z","iopub.status.idle":"2021-06-10T23:35:09.691954Z","shell.execute_reply.started":"2021-06-10T23:35:09.659333Z","shell.execute_reply":"2021-06-10T23:35:09.691161Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                    qid  ...   target\n0  00002165364db923c7e6  ...        0\n1  000032939017120e6e44  ...        0\n2  0000412ca6e4628ce2cf  ...        0\n3  000042bf85aa498cd78e  ...        0\n4  0000455dfa3e01eae3af  ...        0\n\n[5 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>qid</th>\n      <th>question_text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00002165364db923c7e6</td>\n      <td>How did Quebec nationalists see their province...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000032939017120e6e44</td>\n      <td>Do you have an adopted dog, how would you enco...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0000412ca6e4628ce2cf</td>\n      <td>Why does velocity affect time? Does velocity a...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>000042bf85aa498cd78e</td>\n      <td>How did Otto von Guericke used the Magdeburg h...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0000455dfa3e01eae3af</td>\n      <td>Can I convert montra helicon D to a mountain b...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Như ta có thể thấy, bộ dữ liệu có 3 trường là ***qid*** - id của câu hỏi, ***question_text*** - nội dung của  câu hỏi và ***target*** - phân loại câu hỏi bằng hai giá trị là 0, 1 với 0 là các câu hỏi \"Sincere\" và 1 là các câu hỏi \"Insincere\"","metadata":{}},{"cell_type":"markdown","source":"Chúng ta cùng xem qua các câu hỏi **\"Sincere\"**:","metadata":{}},{"cell_type":"code","source":"df_train[df_train['target']==0].head()","metadata":{"execution":{"iopub.status.busy":"2021-06-10T23:35:09.693683Z","iopub.execute_input":"2021-06-10T23:35:09.694178Z","iopub.status.idle":"2021-06-10T23:35:09.783264Z","shell.execute_reply.started":"2021-06-10T23:35:09.693947Z","shell.execute_reply":"2021-06-10T23:35:09.781975Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                    qid  ...   target\n0  00002165364db923c7e6  ...        0\n1  000032939017120e6e44  ...        0\n2  0000412ca6e4628ce2cf  ...        0\n3  000042bf85aa498cd78e  ...        0\n4  0000455dfa3e01eae3af  ...        0\n\n[5 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>qid</th>\n      <th>question_text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00002165364db923c7e6</td>\n      <td>How did Quebec nationalists see their province...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000032939017120e6e44</td>\n      <td>Do you have an adopted dog, how would you enco...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0000412ca6e4628ce2cf</td>\n      <td>Why does velocity affect time? Does velocity a...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>000042bf85aa498cd78e</td>\n      <td>How did Otto von Guericke used the Magdeburg h...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0000455dfa3e01eae3af</td>\n      <td>Can I convert montra helicon D to a mountain b...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Các câu hỏi **\"Insincere\"**:","metadata":{}},{"cell_type":"code","source":"df_train[df_train['target']==1].head()","metadata":{"execution":{"iopub.status.busy":"2021-06-10T23:35:09.784780Z","iopub.execute_input":"2021-06-10T23:35:09.785376Z","iopub.status.idle":"2021-06-10T23:35:09.816847Z","shell.execute_reply.started":"2021-06-10T23:35:09.785064Z","shell.execute_reply":"2021-06-10T23:35:09.815797Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                      qid  ...   target\n22   0000e91571b60c2fb487  ...        1\n30   00013ceca3f624b09f42  ...        1\n110  0004a7fcb2bf73076489  ...        1\n114  00052793eaa287aff1e1  ...        1\n115  000537213b01fd77b58a  ...        1\n\n[5 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>qid</th>\n      <th>question_text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>22</th>\n      <td>0000e91571b60c2fb487</td>\n      <td>Has the United States become the largest dicta...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>00013ceca3f624b09f42</td>\n      <td>Which babies are more sweeter to their parents...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>110</th>\n      <td>0004a7fcb2bf73076489</td>\n      <td>If blacks support school choice and mandatory ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>114</th>\n      <td>00052793eaa287aff1e1</td>\n      <td>I am gay boy and I love my cousin (boy). He is...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>115</th>\n      <td>000537213b01fd77b58a</td>\n      <td>Which races have the smallest penis?</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"### 2.a.iii Phân bố câu hỏi trong tập dữ liệu","metadata":{}},{"cell_type":"code","source":"sin = len(df_train[df_train[\"target\"]==0])\ninsin = len(df_train[df_train[\"target\"]==1])\npersin = (sin/(sin+insin))*100\nperinsin = (insin/(sin+insin))*100            \nprint(\"# Sincere questions: {:,}({:.2f}%) and # Insincere questions: {:,}({:.2f}%)\".format(sin,persin,insin,perinsin))\n# print(\"Sinsere:{}% Insincere: {}%\".format(round(persin,2),round(perinsin,2)))\nprint(\"# Test samples: {:,}({:.3f}% of train samples)\".format(len(df_test),len(df_test)/len(df_train)))","metadata":{"execution":{"iopub.status.busy":"2021-06-10T23:35:09.818338Z","iopub.execute_input":"2021-06-10T23:35:09.818884Z","iopub.status.idle":"2021-06-10T23:35:09.931349Z","shell.execute_reply.started":"2021-06-10T23:35:09.818595Z","shell.execute_reply":"2021-06-10T23:35:09.930369Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"# Sincere questions: 1,225,312(93.81%) and # Insincere questions: 80,810(6.19%)\n# Test samples: 375,806(0.288% of train samples)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Vậy **\"Sincere question\"** có hơn **1,2 triệu** câu hỏi, chiếm **93.81%** tập train, còn lại **6.19%** cho **\"Insincere question\"** với khoảng gần **81,000** câu hỏi. Ta có thể thấy lượng data bị chênh lệch rất nhiều khi **sincere question** nhiều hơn **15 lần** so với **insincere question**. Cũng không quá bất ngờ khi hiện tượng này vẫn hay xảy ra trong các bài toán *machine learning*. Tuy nhiên nó lại gây ảnh hưởng đến độ chính xác của *model*. Vì vậy, em sẽ xử dụng **K-Fold Cross Validation** và **F1 Score** để ứng phó với nó để độ chính xác của mô hình không bị ảnh hưởng.\n\n**Nhận xét:**\n\n<!-- Đầu vào của mô hình đang ở dạng text chứ không phải các con số, sự thật là chúng ta không thể đem trực tiếp dữ liệu chữ viết thô vào để huấn luyện mô hình máy học ngay được, bởi vì các mô hình máy học chỉ làm việc được trên những con số, hay chính xác hơn là tính toán trên các ma trận, véc-tơ số. Vì vậy, bước tiếp theo em sẽ xử lý văn bản đầu vào bằng kỹ thuaembedding để đưa dữ liệu ban đầu thành dạng các vector nhiều chiều. -->\n\nSau khi quan sát qua dữ liệu, em nhận thấy dữ liệu có một số điểm cần phải được xử lý, chuẩn hóa lại như: \n* Một số câu hỏi sử dụng sai, lẫn lộn giữa chữ **in hoa và in thường**\n* Nhiều câu chứa một số **ký tự đặc biệt** như \"<\", \"/\",...\n* Nhiều câu được cấu thành lẫn lộn từ **chữ và số**\n* Nhiều câu sử dụng các cụm từ **viết tắt** như \"ain't\", \"isn't\", \"she's\"\n\nVậy chúng ta cùng đến bước chuẩn hóa (*normalize*) các câu hỏi đầu vào.","metadata":{}},{"cell_type":"markdown","source":"## 2.b Normalization\n\nTham khảo tại:\n* How to: Preprocessing when using embeddings: https://www.kaggle.com/christofhenkel/how-to-preprocessing-when-using-embeddings\n* Improve your Score with some Text Preprocessing: https://www.kaggle.com/theoviel/improve-your-score-with-some-text-preprocessing\n* Một vài phần em tham khảo thêm tại: https://github.com/wongchunghang/toxic-comment-challenge-lstm/blob/master/toxic_comment_9872_model.ipynb","metadata":{"_uuid":"07e9890ec0b490cef57565f7dff953aa56ebd3dc"}},{"cell_type":"markdown","source":"### 2.b.i Xây dựng một số hàm chuẩn hóa","metadata":{}},{"cell_type":"markdown","source":"Như vấn đề đã nêu ở trên, ở bước này em sẽ tiến hành xử lý **chữ hoa và chữ thường**, các **ký tự đặc biệt**, các **chữ số** và các kiểu **viết tắt**. \nĐầu tiên, ta xây dựng một số hàm cơ bản như sau: \n* **clean_text()**: xử lý các **ký tự đặc biệt** tồn tại trong văn bản đầu vào, các ký tự đặc biệt được lấy từ mảng **puncts[]** bên dưới.\n* **clean_numbers()**: xử lý các **chữ số** trong văn bản đầu vào. \n* **replace_typical_misspell()**: xử lý các từ **viết tắt** trong câu hỏi đầu vào bằng cách **thay thế** chúng trong **mispell_dict** được khai báo ở dưới. ","metadata":{}},{"cell_type":"code","source":"puncts = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '@', '£', \n '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',  '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', \n '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', \n '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', 'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', \n '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√', ]\n\ndef clean_text(x):\n    x = str(x)\n#     print(\"Before clean_text(): \" + x)\n    for punct in puncts:\n        x = x.replace(punct, f' {punct} ')\n    return x\n#     print(\"After clean_text()\" + x)\n\ndef clean_numbers(x):\n    x = re.sub('[0-9]{5,}', '#####', x)\n    x = re.sub('[0-9]{4}', '####', x)\n    x = re.sub('[0-9]{3}', '###', x)\n    x = re.sub('[0-9]{2}', '##', x)\n    return x\n\nmispell_dict = {\n   \"ain't\":\"is not\",\n   \"aren't\":\"are not\",\n   \"can't\":\"cannot\",\n   \"'cause\":\"because\",\n   \"could've\":\"could have\",\n   \"couldn't\":\"could not\",\n   \"didn't\":\"did not\",\n   \"doesn't\":\"does not\",\n   \"don't\":\"do not\",\n   \"hadn't\":\"had not\",\n   \"hasn't\":\"has not\",\n   \"haven't\":\"have not\",\n   \"he'd\":\"he would\",\n   \"he'll\":\"he will\",\n   \"he's\":\"he is\",\n   \"how'd\":\"how did\",\n   \"how'd'y\":\"how do you\",\n   \"how'll\":\"how will\",\n   \"how's\":\"how is\",\n   \"I'd\":\"I would\",\n   \"I'd've\":\"I would have\",\n   \"I'll\":\"I will\",\n   \"I'll've\":\"I will have\",\n   \"I'm\":\"I am\",\n   \"I've\":\"I have\",\n   \"i'd\":\"i would\",\n   \"i'd've\":\"i would have\",\n   \"i'll\":\"i will\",\n   \"i'll've\":\"i will have\",\n   \"i'm\":\"i am\",\n   \"i've\":\"i have\",\n   \"isn't\":\"is not\",\n   \"it'd\":\"it would\",\n   \"it'd've\":\"it would have\",\n   \"it'll\":\"it will\",\n   \"it'll've\":\"it will have\",\n   \"it's\":\"it is\",\n   \"let's\":\"let us\",\n   \"ma'am\":\"madam\",\n   \"mayn't\":\"may not\",\n   \"might've\":\"might have\",\n   \"mightn't\":\"might not\",\n   \"mightn't've\":\"might not have\",\n   \"must've\":\"must have\",\n   \"mustn't\":\"must not\",\n   \"mustn't've\":\"must not have\",\n   \"needn't\":\"need not\",\n   \"needn't've\":\"need not have\",\n   \"o'clock\":\"of the clock\",\n   \"oughtn't\":\"ought not\",\n   \"oughtn't've\":\"ought not have\",\n   \"shan't\":\"shall not\",\n   \"sha'n't\":\"shall not\",\n   \"shan't've\":\"shall not have\",\n   \"she'd\":\"she would\",\n   \"she'd've\":\"she would have\",\n   \"she'll\":\"she will\",\n   \"she'll've\":\"she will have\",\n   \"she's\":\"she is\",\n   \"should've\":\"should have\",\n   \"shouldn't\":\"should not\",\n   \"shouldn't've\":\"should not have\",\n   \"so've\":\"so have\",\n   \"so's\":\"so as\",\n   \"this's\":\"this is\",\n   \"that'd\":\"that would\",\n   \"that'd've\":\"that would have\",\n   \"that's\":\"that is\",\n   \"there'd\":\"there would\",\n   \"there'd've\":\"there would have\",\n   \"there's\":\"there is\",\n   \"here's\":\"here is\",\n   \"they'd\":\"they would\",\n   \"they'd've\":\"they would have\",\n   \"they'll\":\"they will\",\n   \"they'll've\":\"they will have\",\n   \"they're\":\"they are\",\n   \"they've\":\"they have\",\n   \"to've\":\"to have\",\n   \"wasn't\":\"was not\",\n   \"we'd\":\"we would\",\n   \"we'd've\":\"we would have\",\n   \"we'll\":\"we will\",\n   \"we'll've\":\"we will have\",\n   \"we're\":\"we are\",\n   \"we've\":\"we have\",\n   \"weren't\":\"were not\",\n   \"what'll\":\"what will\",\n   \"what'll've\":\"what will have\",\n   \"what're\":\"what are\",\n   \"what's\":\"what is\",\n   \"what've\":\"what have\",\n   \"when's\":\"when is\",\n   \"when've\":\"when have\",\n   \"where'd\":\"where did\",\n   \"where's\":\"where is\",\n   \"where've\":\"where have\",\n   \"who'll\":\"who will\",\n   \"who'll've\":\"who will have\",\n   \"who's\":\"who is\",\n   \"who've\":\"who have\",\n   \"why's\":\"why is\",\n   \"why've\":\"why have\",\n   \"will've\":\"will have\",\n   \"won't\":\"will not\",\n   \"won't've\":\"will not have\",\n   \"would've\":\"would have\",\n   \"wouldn't\":\"would not\",\n   \"wouldn't've\":\"would not have\",\n   \"y'all\":\"you all\",\n   \"y'all'd\":\"you all would\",\n   \"y'all'd've\":\"you all would have\",\n   \"y'all're\":\"you all are\",\n   \"y'all've\":\"you all have\",\n   \"you'd\":\"you would\",\n   \"you'd've\":\"you would have\",\n   \"you'll\":\"you will\",\n   \"you'll've\":\"you will have\",\n   \"you're\":\"you are\",\n   \"you've\":\"you have\",\n   \"colour\":\"color\",\n   \"centre\":\"center\",\n   \"favourite\":\"favorite\",\n   \"travelling\":\"traveling\",\n   \"counselling\":\"counseling\",\n   \"theatre\":\"theater\",\n   \"cancelled\":\"canceled\",\n   \"labour\":\"labor\",\n   \"organisation\":\"organization\",\n   \"wwii\":\"world war 2\",\n   \"citicise\":\"criticize\",\n   \"youtu \":\"youtube \",\n   \"Qoura\":\"Quora\",\n   \"sallary\":\"salary\",\n   \"Whta\":\"What\",\n   \"narcisist\":\"narcissist\",\n   \"howdo\":\"how do\",\n   \"whatare\":\"what are\",\n   \"howcan\":\"how can\",\n   \"howmuch\":\"how much\",\n   \"howmany\":\"how many\",\n   \"whydo\":\"why do\",\n   \"doI\":\"do I\",\n   \"theBest\":\"the best\",\n   \"howdoes\":\"how does\",\n   \"mastrubation\":\"masturbation\",\n   \"mastrubate\":\"masturbate\",\n   \"mastrubating\":\"masturbating\",\n   \"pennis\":\"penis\",\n   \"Etherium\":\"Ethereum\",\n   \"narcissit\":\"narcissist\",\n   \"bigdata\":\"big data\",\n   \"2k17\":\"2017\",\n   \"2k18\":\"2018\",\n   \"qouta\":\"quota\",\n   \"exboyfriend\":\"ex boyfriend\",\n   \"airhostess\":\"air hostess\",\n   \"whst\":\"what\",\n   \"watsapp\":\"whatsapp\",\n   \"demonitisation\":\"demonetization\",\n   \"demonitization\":\"demonetization\",\n   \"demonetisation\":\"demonetization\"\n}\ndef _get_mispell(mispell_dict):\n    mispell_re = re.compile('(%s)' % '|'.join(mispell_dict.keys()))\n    return mispell_dict, mispell_re\n\nmispellings, mispellings_re = _get_mispell(mispell_dict)\ndef replace_typical_misspell(text):\n    def replace(match):\n        return mispellings[match.group(0)]\n    return mispellings_re.sub(replace, text)","metadata":{"_uuid":"abeab4c80d6829cf2eae706bfa7929e2871af81f","scrolled":true,"execution":{"iopub.status.busy":"2021-06-10T23:35:09.932987Z","iopub.execute_input":"2021-06-10T23:35:09.933530Z","iopub.status.idle":"2021-06-10T23:35:10.294473Z","shell.execute_reply.started":"2021-06-10T23:35:09.933238Z","shell.execute_reply":"2021-06-10T23:35:10.293754Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"### 2.b.ii Chuẩn hóa dữ liệu\n\nQuá trình chuẩn hóa đầu vào cho từng câu hỏi được xử lý như sau: \n1. Chuyển hết tất cả các ký tự trong câu hỏi về dạng viết thường (# **Lower**)\n2. Xử các ký tự đặc biệt khỏi từng câu hỏi (# **Clean the text**)\n3. Xử lý các chữ số nằm trong từng câu hỏi (# **Clean numbers**)\n4. Thay thế các từ viết tắt thành dạng nguyên bản của chúng (# **Clean spellings**)\n5. Thay thế các giá trị null trong cột question_text bằng giá trị \"_##_\" (# **Fill up the missing values**)\n6. Thêm một số trường dữ liệu cho dataset ban đầu (# **Add features**)\n7. **Tokenize** train data và test data: Vì dữ liệu đầu vào ở dạng text nên máy không thể hiểu được, để máy có thể dễ dàng hiểu được dữ liệu này hơn, chúng ta cần **break** từng từ ra thành nhiều thành phần khác nhau, việc làm này gọi là tokenize, đây là một kỹ thuật rất quan trọng trong xử lý dữ liệu văn bản. \n8. **Padding** data: vì dữ liệu đầu vào của ta là dạng text nên chắc chắn sẽ có câu dài câu ngắn. Tuy nhiên, mô hình học máy em dùng ở dưới là LSTM, nó yêu cầu dữ liệu đầu vào phải có **cùng độ dài**. Vì vậy, việc thêm thắt sao cho các câu có cùng độ dài là cần thiết, việc là này được gọi là padding. \n9. **Shuffle** data: trộn train data và test data lên một cách ngẫu nhiên. ","metadata":{"_uuid":"3c09d981ae674e6a373189a04dba8d0932b0765b"}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\n# Add features\ndef add_features(df):\n    \n    df['question_text'] = df['question_text'].progress_apply(lambda x:str(x))\n    df['total_length'] = df['question_text'].progress_apply(len)\n    df['capitals'] = df['question_text'].progress_apply(lambda comment: sum(1 for c in comment if c.isupper()))\n    df['caps_vs_length'] = df.progress_apply(lambda row: float(row['capitals'])/float(row['total_length']),\n                                axis=1)\n    df['num_words'] = df.question_text.str.count('\\S+')\n    df['num_unique_words'] = df['question_text'].progress_apply(lambda comment: len(set(w for w in comment.split())))\n    df['words_vs_unique'] = df['num_unique_words'] / df['num_words']  \n\n    return df\n\ndef load_and_prec():\n    train_df = df_train\n    test_df = df_test\n    print(\"Train shape : \",train_df.shape)\n    print(\"Test shape : \",test_df.shape)\n    \n    # Lower\n    train_df[\"question_text\"] = train_df[\"question_text\"].apply(lambda x: x.lower())\n    test_df[\"question_text\"] = test_df[\"question_text\"].apply(lambda x: x.lower())\n\n    # Clean the text\n    train_df[\"question_text\"] = train_df[\"question_text\"].progress_apply(lambda x: clean_text(x))\n    test_df[\"question_text\"] = test_df[\"question_text\"].apply(lambda x: clean_text(x))\n    \n    # Clean numbers\n    train_df[\"question_text\"] = train_df[\"question_text\"].progress_apply(lambda x: clean_numbers(x))\n    test_df[\"question_text\"] = test_df[\"question_text\"].apply(lambda x: clean_numbers(x))\n    \n    # Clean speelings\n    train_df[\"question_text\"] = train_df[\"question_text\"].progress_apply(lambda x: replace_typical_misspell(x))\n    test_df[\"question_text\"] = test_df[\"question_text\"].apply(lambda x: replace_typical_misspell(x))\n    \n    # Fill up the missing values\n    train_X = train_df[\"question_text\"].fillna(\"_##_\").values\n    test_X = test_df[\"question_text\"].fillna(\"_##_\").values\n\n\n    \n    ###################### Add Features ###############################\n    #  https://github.com/wongchunghang/toxic-comment-challenge-lstm/blob/master/toxic_comment_9872_model.ipynb\n    train = add_features(train_df)\n    test = add_features(test_df)\n    \n    features = train[['caps_vs_length', 'words_vs_unique']].fillna(0)\n    test_features = test[['caps_vs_length', 'words_vs_unique']].fillna(0)\n\n    ss = StandardScaler()\n    ss.fit(np.vstack((features, test_features)))\n    features = ss.transform(features)\n    test_features = ss.transform(test_features)\n    ###########################################################################\n\n    ## Tokenize the sentences\n    tokenizer = Tokenizer(num_words=max_features)\n    tokenizer.fit_on_texts(list(train_X))\n    train_X = tokenizer.texts_to_sequences(train_X)\n    test_X = tokenizer.texts_to_sequences(test_X)\n\n    ## Pad the sentences \n    train_X = pad_sequences(train_X, maxlen=maxlen)\n    test_X = pad_sequences(test_X, maxlen=maxlen)\n\n    ## Get the target values\n    train_y = train_df['target'].values\n    \n#     # Splitting to training and a final test set    \n#     train_X, x_test_f, train_y, y_test_f = train_test_split(list(zip(train_X,features)), train_y, test_size=0.2, random_state=SEED)    \n#     train_X, features = zip(*train_X)\n#     x_test_f, features_t = zip(*x_test_f)    \n    \n    #shuffling the data\n    np.random.seed(SEED)\n    trn_idx = np.random.permutation(len(train_X))\n\n    train_X = train_X[trn_idx]\n    train_y = train_y[trn_idx]\n    features = features[trn_idx]\n    \n    return train_X, test_X, train_y, features, test_features, tokenizer.word_index\n#     return train_X, test_X, train_y, x_test_f,y_test_f,features, test_features, features_t, tokenizer.word_index\n#     return train_X, test_X, train_y, tokenizer.word_index","metadata":{"_uuid":"63cb21525251b060aeb309e7be4b48772f8720f5","scrolled":true,"execution":{"iopub.status.busy":"2021-06-10T23:35:10.296296Z","iopub.execute_input":"2021-06-10T23:35:10.296801Z","iopub.status.idle":"2021-06-10T23:35:10.315229Z","shell.execute_reply.started":"2021-06-10T23:35:10.296595Z","shell.execute_reply":"2021-06-10T23:35:10.314305Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"x_train, x_test, y_train, features, test_features, word_index = load_and_prec() ","metadata":{"_uuid":"3c72fcddb4f680879e231c3dbfc0c71e27fc424c","scrolled":true,"execution":{"iopub.status.busy":"2021-06-10T23:35:10.316797Z","iopub.execute_input":"2021-06-10T23:35:10.317387Z","iopub.status.idle":"2021-06-10T23:40:40.524671Z","shell.execute_reply.started":"2021-06-10T23:35:10.317085Z","shell.execute_reply":"2021-06-10T23:40:40.523931Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Train shape :  (1306122, 3)\nTest shape :  (375806, 2)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(IntProgress(value=0, description='Progress', max=1306122, style=ProgressStyle(description_width…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"09554ff4abcb464688c46dda95fe2562"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(IntProgress(value=0, description='Progress', max=1306122, style=ProgressStyle(description_width…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f32693ce9a446a1ae5e24dc54b617c2"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(IntProgress(value=0, description='Progress', max=1306122, style=ProgressStyle(description_width…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3fc73b04c7a94cca8c909912f7b4abe1"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(IntProgress(value=0, description='Progress', max=1306122, style=ProgressStyle(description_width…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dfd3a82e721349bbaa742d4e3c427fed"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(IntProgress(value=0, description='Progress', max=1306122, style=ProgressStyle(description_width…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ebf0a541c1814798ac27738ae1036804"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(IntProgress(value=0, description='Progress', max=1306122, style=ProgressStyle(description_width…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"80d818818d324ec1bf19e3b3db9edcf3"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(IntProgress(value=0, description='Progress', max=1306122, style=ProgressStyle(description_width…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef5c88fe1cdd4abda172e7c4ab03bc40"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(IntProgress(value=0, description='Progress', max=1306122, style=ProgressStyle(description_width…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"45d4620012604a90935b27d136a9f2a3"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(IntProgress(value=0, description='Progress', max=375806, style=ProgressStyle(description_width=…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dd8cbfc0babc423ead33fb4aa71129e4"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(IntProgress(value=0, description='Progress', max=375806, style=ProgressStyle(description_width=…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a7fb284508504ccd8049eb447358e075"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(IntProgress(value=0, description='Progress', max=375806, style=ProgressStyle(description_width=…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f7bb24eb609a44e68b5935aef0ad1b7e"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(IntProgress(value=0, description='Progress', max=375806, style=ProgressStyle(description_width=…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"662197a7ffd0411e8abc3782bc40fe99"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(IntProgress(value=0, description='Progress', max=375806, style=ProgressStyle(description_width=…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e3f31102c154bd6a2b772ea849c9980"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Chúng ta cùng **xem lại** dữ liệu **sau** khi được **chuẩn hóa**:","metadata":{}},{"cell_type":"code","source":"print(x_train.shape)\nprint(x_train)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T23:40:40.526028Z","iopub.execute_input":"2021-06-10T23:40:40.526291Z","iopub.status.idle":"2021-06-10T23:40:40.534896Z","shell.execute_reply.started":"2021-06-10T23:40:40.526246Z","shell.execute_reply":"2021-06-10T23:40:40.531657Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"(1306122, 70)\n[[    0     0     0 ...    49    12 55568]\n [    0     0     0 ...    35   199    18]\n [    0     0     0 ...    58   134   169]\n ...\n [    0     0     0 ...   234  2329   288]\n [    0     0     0 ...     6   412  7924]\n [    0     0     0 ...    11     8    11]]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### 2.b.iii Lưu dữ liệu đã được chuẩn hóa","metadata":{"_uuid":"5264b1a511613e0cb9cffc11e93e906f932be191"}},{"cell_type":"code","source":"np.save(\"x_train\",x_train)\nnp.save(\"x_test\",x_test)\nnp.save(\"y_train\",y_train)\n\nnp.save(\"features\",features)\nnp.save(\"test_features\",test_features)\nnp.save(\"word_index.npy\",word_index)","metadata":{"_uuid":"7dc2704001695c0d691fec74cc111308da3fc340","scrolled":true,"execution":{"iopub.status.busy":"2021-06-10T23:40:40.536387Z","iopub.execute_input":"2021-06-10T23:40:40.536971Z","iopub.status.idle":"2021-06-10T23:40:40.947538Z","shell.execute_reply.started":"2021-06-10T23:40:40.536809Z","shell.execute_reply":"2021-06-10T23:40:40.946827Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"!ls \"/kaggle/working\"","metadata":{"execution":{"iopub.status.busy":"2021-06-10T23:40:40.949169Z","iopub.execute_input":"2021-06-10T23:40:40.949617Z","iopub.status.idle":"2021-06-10T23:40:41.731293Z","shell.execute_reply.started":"2021-06-10T23:40:40.949407Z","shell.execute_reply":"2021-06-10T23:40:41.730441Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"__notebook_source__.ipynb  test_features.npy  x_test.npy   y_train.npy\nfeatures.npy\t\t   word_index.npy     x_train.npy\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### 2.b.iv Load lại dữ liệu đã được chuẩn hóa","metadata":{"_uuid":"ef622350c3ac00bcbea516ccf7dffbeca7b4cc39"}},{"cell_type":"code","source":"# save np.load\nnp_load_old = np.load\n\n# modify the default parameters of np.load\nnp.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)\n\nx_train = np.load(\"x_train.npy\")\nx_test = np.load(\"x_test.npy\")\ny_train = np.load(\"y_train.npy\")\nfeatures = np.load(\"features.npy\")\ntest_features = np.load(\"test_features.npy\")\nword_index = np.load(\"word_index.npy\").item()\n# restore np.load for future normal usage\nnp.load = np_load_old","metadata":{"_uuid":"6e1f33f0d744e86cfbcc21b8e696bb568ba1c454","scrolled":true,"execution":{"iopub.status.busy":"2021-06-10T23:40:41.734672Z","iopub.execute_input":"2021-06-10T23:40:41.734914Z","iopub.status.idle":"2021-06-10T23:40:42.091109Z","shell.execute_reply.started":"2021-06-10T23:40:41.734871Z","shell.execute_reply":"2021-06-10T23:40:42.090358Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"features","metadata":{"_uuid":"6db7b1d3f22a6e35699d9f0dbb51343e249d9ee7","scrolled":true,"execution":{"iopub.status.busy":"2021-06-10T23:40:42.092499Z","iopub.execute_input":"2021-06-10T23:40:42.092768Z","iopub.status.idle":"2021-06-10T23:40:42.100308Z","shell.execute_reply.started":"2021-06-10T23:40:42.092724Z","shell.execute_reply":"2021-06-10T23:40:42.099269Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"array([[-1.44394974e-03,  6.55694761e-01],\n       [-1.44394974e-03, -2.13835742e+00],\n       [-1.44394974e-03,  4.82921137e-02],\n       ...,\n       [-1.44394974e-03,  6.55694761e-01],\n       [-1.44394974e-03,  6.55694761e-01],\n       [-1.44394974e-03, -1.55013591e+00]])"},"metadata":{}}]},{"cell_type":"code","source":"dict(list(word_index.items())[0:10])","metadata":{"execution":{"iopub.status.busy":"2021-06-10T23:40:42.102058Z","iopub.execute_input":"2021-06-10T23:40:42.102465Z","iopub.status.idle":"2021-06-10T23:40:42.134483Z","shell.execute_reply.started":"2021-06-10T23:40:42.102304Z","shell.execute_reply":"2021-06-10T23:40:42.133591Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"{'the': 1,\n 'what': 2,\n 'is': 3,\n 'a': 4,\n 'to': 5,\n 'in': 6,\n 'of': 7,\n 'i': 8,\n 'how': 9,\n 'and': 10}"},"metadata":{}}]},{"cell_type":"markdown","source":"**Nhận xét:**\n\nSự thật là chúng ta **không thể** đem trực tiếp **dữ liệu** chữ viết **thô** vào để huấn luyện **mô hình học máy** ngay được, bởi vì các mô hình máy học **chỉ** làm việc được trên những **con số**, hay chính xác hơn là tính toán trên các **ma trận**, **véc-tơ số**.Tuy nhiên **sau** khi **chuẩn hóa**, dữ liệu của chúng ta đã **không** còn ở dạng **text** nên đã **có thể** đưa vào các mô hình học máy để **train**. Nhưng ở bước tiếp theo em sẽ xử lý **thêm** văn bản đầu vào bằng kỹ thuật **embedding** để đưa dữ liệu ban đầu thành dạng các **vector nhiều chiều** vì đây là một kỹ thuật được sử dụng rất hiệu quả trong các bài toán xử lý ngôn ngữ tự nhiên. ","metadata":{}},{"cell_type":"markdown","source":"## 2.c Embedding","metadata":{}},{"cell_type":"markdown","source":"Hiện nay, một số kĩ thuật *Embedding* được sử dụng phổ biến như mạng *Neural Network*, *PCA* *(Principal Component Analysis)* gọi là kĩ thuật phân tích thành phần chính, *TF-IDF, Bag of Word, Encoder-Decoder* sử dụng trong *RNN* (*Recurrent Neural Network*) hoặc *LSTM (Long-Short Term Memory), *...\n\nTuy nhiên, trong cuộc thi này, ***Kaggle*** đã **cung cấp** một số thư viện sử dụng kĩ thuật Embedding như **glove, wiki-news (fasttext), paragram** và **GoogleNews** nên em sẽ sử dụng luôn.","metadata":{}},{"cell_type":"code","source":"!unzip ../input/embeddings","metadata":{"execution":{"iopub.status.busy":"2021-06-10T23:40:42.136249Z","iopub.execute_input":"2021-06-10T23:40:42.136722Z","iopub.status.idle":"2021-06-10T23:44:20.540020Z","shell.execute_reply.started":"2021-06-10T23:40:42.136512Z","shell.execute_reply":"2021-06-10T23:44:20.539279Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Archive:  ../input/embeddings.zip\n   creating: GoogleNews-vectors-negative300/\n   creating: glove.840B.300d/\n   creating: paragram_300_sl999/\n   creating: wiki-news-300d-1M/\n  inflating: glove.840B.300d/glove.840B.300d.txt  \n  inflating: GoogleNews-vectors-negative300/GoogleNews-vectors-negative300.bin  \n  inflating: wiki-news-300d-1M/wiki-news-300d-1M.vec  \n  inflating: paragram_300_sl999/README.txt  \n  inflating: paragram_300_sl999/paragram_300_sl999.txt  \n","output_type":"stream"}]},{"cell_type":"code","source":"!ls \"/kaggle/working\"","metadata":{"execution":{"iopub.status.busy":"2021-06-10T23:44:20.541481Z","iopub.execute_input":"2021-06-10T23:44:20.541764Z","iopub.status.idle":"2021-06-10T23:44:21.235104Z","shell.execute_reply.started":"2021-06-10T23:44:20.541717Z","shell.execute_reply":"2021-06-10T23:44:21.234056Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"GoogleNews-vectors-negative300\tparagram_300_sl999  x_test.npy\n__notebook_source__.ipynb\ttest_features.npy   x_train.npy\nfeatures.npy\t\t\twiki-news-300d-1M   y_train.npy\nglove.840B.300d\t\t\tword_index.npy\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Như thầy có thể thấy sau khi giải nén tập embedding, chúng ta có thể sử dụng các thư viện trong đường dẫn trên.\n","metadata":{}},{"cell_type":"markdown","source":"### 2.c.i Load Embedding\nTrong bài này, em sẽ **sử dụng** 3 thư viện embedding là **glove** - được phát triển bời Google, **fasttext** - được phát triển bởi Facebook và **paragram**. \n\nTham khảo tại: https://www.kaggle.com/gmhost/gru-capsule\n<!-- \nhttps://ichi.pro/vi/nhung-word2vec-glove-fasttext-va-baseline-word-tung-buoc-229010274898187\n\nhttps://www.kaggle.com/sudalairajkumar/a-look-at-different-embeddings -->\n","metadata":{}},{"cell_type":"code","source":"def load_glove(word_index):\n    EMBEDDING_FILE = './glove.840B.300d/glove.840B.300d.txt'\n    def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')[:300]\n    embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE))\n    \n    all_embs = np.stack(embeddings_index.values())\n    emb_mean,emb_std = -0.005838499,0.48782197\n    embed_size = all_embs.shape[1]\n\n    # word_index = tokenizer.word_index\n    nb_words = min(max_features, len(word_index))\n    embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n    for word, i in word_index.items():\n        if i >= max_features: continue\n        embedding_vector = embeddings_index.get(word)\n        if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n            \n    return embedding_matrix \n    \ndef load_fasttext(word_index):\n    EMBEDDING_FILE = './wiki-news-300d-1M/wiki-news-300d-1M.vec'\n    def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n    embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE) if len(o)>100)\n\n    all_embs = np.stack(embeddings_index.values())\n    emb_mean,emb_std = all_embs.mean(), all_embs.std()\n    embed_size = all_embs.shape[1]\n\n    # word_index = tokenizer.word_index\n    nb_words = min(max_features, len(word_index))\n    embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n    #embedding_matrix = np.random.normal(emb_mean, 0, (nb_words, embed_size))\n    for word, i in word_index.items():\n        if i >= max_features: continue\n        embedding_vector = embeddings_index.get(word)\n        if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n\n    return embedding_matrix\n\ndef load_para(word_index):\n    EMBEDDING_FILE = './paragram_300_sl999/paragram_300_sl999.txt'\n    def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n    embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE, encoding=\"utf8\", errors='ignore') if len(o)>100)\n\n    all_embs = np.stack(embeddings_index.values())\n    emb_mean,emb_std = -0.0053247833,0.49346462\n    embed_size = all_embs.shape[1]\n\n    # word_index = tokenizer.word_index\n    nb_words = min(max_features, len(word_index))\n    embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n    #embedding_matrix = np.random.normal(emb_mean, 0, (nb_words, embed_size))\n    for word, i in word_index.items():\n        if i >= max_features: continue\n        embedding_vector = embeddings_index.get(word)\n        if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n    \n    return embedding_matrix","metadata":{"execution":{"iopub.status.busy":"2021-06-10T23:44:21.239818Z","iopub.execute_input":"2021-06-10T23:44:21.241969Z","iopub.status.idle":"2021-06-10T23:44:22.982539Z","shell.execute_reply.started":"2021-06-10T23:44:21.241917Z","shell.execute_reply":"2021-06-10T23:44:22.981532Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# missing entries in the embedding are set using np.random.normal so we have to seed here too\nseed_everything()\nglove_embeddings = load_glove(word_index)\nparagram_embeddings = load_para(word_index)\nfasttext_embeddings = load_fasttext(word_index)\n\nembedding_matrix = np.mean([glove_embeddings, paragram_embeddings, fasttext_embeddings], axis=0)\n\ndel glove_embeddings, paragram_embeddings, fasttext_embeddings\ngc.collect()","metadata":{"_uuid":"6a5f4502324d369ff6faa3692accee4f8a233005","scrolled":true,"execution":{"iopub.status.busy":"2021-06-10T23:44:22.983882Z","iopub.execute_input":"2021-06-10T23:44:22.984156Z","iopub.status.idle":"2021-06-10T23:54:00.184239Z","shell.execute_reply.started":"2021-06-10T23:44:22.984098Z","shell.execute_reply":"2021-06-10T23:54:00.183252Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:6: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n  \n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:45: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:25: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n","output_type":"stream"},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":"np.shape(embedding_matrix)","metadata":{"_uuid":"2484f29f159af679af7d7745e522221e31e42ce0","execution":{"iopub.status.busy":"2021-06-10T23:54:00.185542Z","iopub.execute_input":"2021-06-10T23:54:00.185969Z","iopub.status.idle":"2021-06-10T23:54:00.191869Z","shell.execute_reply.started":"2021-06-10T23:54:00.185787Z","shell.execute_reply":"2021-06-10T23:54:00.190929Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"(185777, 300)"},"metadata":{}}]},{"cell_type":"markdown","source":"# 3. Chuẩn bị mô hình ","metadata":{}},{"cell_type":"markdown","source":"Có thể thấy đây là bài toán phân loại nhị phân, nhưng lại liên quan đến xử lý ngôn ngữ tự nhiên nhiều. Mà gần đây, mô hình **LSTM** cùng với **Attention** đang đạt được rất nhiều thành tựu trong lĩnh vực này. Vì vậy em quyết định chọn mô hình **LSTM** cùng một lớp **Attention**. Ngoài ra, em cũng thêm một số **features** được lấy từ bài thắng cuộc của một cuộc thi phân loại \"toxic comments\". Cùng với đó là việc sử dụng **K-Fold Cross Validation**, **Cyclic Learning Rate**, **GRU** và **Capsule Layer**.\n\nTham khảo tại: https://www.kaggle.com/ziliwang/baseline-pytorch-bilstm","metadata":{}},{"cell_type":"markdown","source":"## 3.a K-Fold Cross Validation \n**Vấn đề**\n\nỞ trên, chúng ta đã nhận định rằng lượng **data** chúng ta có **không** hề **thiếu** hụt về mặt **số lượng**. Tuy nhiên, data của chúng ta **không** hề **cân bằng** khi chênh **lệch** nhau lên đến **15** lần. \n\nMà khi train một model, ta thường **chia** data cho **training set/validation set** theo tỷ lệ 80/20, 70/30 hoặc 90/10 tùy trường hợp. Từ đó, ta có thể thấy dữ liệu tập training set/validation test lệch nhau nhiều nhất là gấp **9** lần. Vấn đề ở đây là tất cả dữ liệu label 1 - insincere question lại có khả năng rơi gần hết vào validation set ta phân chia ra như trên vì số lượng của nó khá bé, đủ để nằm gọn trong tập dữ liệu đó. Nếu xảy ra trường hợp đó, model của chúng ta do **không có cơ hội học hỏi** từ dữ liệu đó nên nó **không thể phân loại** được các câu hỏi label 1. Đó là một điều rất rất kinh khủng. Tuy điều này có xác suất xảy ra thấp nhưng nó vẫn có thể xảy ra do việc chia dữ liệu cho tập training và validation là hoàn toàn ngẫu nhiên.\n\nĐể giải quyết vấn đề này, em sẽ sử dụng **K-Fold Cross Validation**\n\n<img src=\"https://scikit-learn.org/stable/_images/grid_search_cross_validation.png\" width=900>","metadata":{"_uuid":"d3b707858357eec18403f97368a40c43987b40e8"}},{"cell_type":"markdown","source":"*K-Fold Cross Validation* là một phương pháp đánh giá *model* một cách chính xác khi chúng ta train model nhưng có quá **ít dữ liệu** hoặc dữ liệu bị **chênh lệch** quá nhiều (*imbalance*). \n\nNhư hình bên trên, ta thấy dữ liệu được chia thành:\n* Test data ta để nguyên, không đả động gì đến.\n* Training data ta chia thành **K** phần. Sau đó train model K lần, mỗi lần train sẽ chọn **1** phần làm dữ liệu **validation** và **K-1** phần còn lại làm dữ liệu **training**. Kết quả đánh giá model cuối cùng là **trung bình cộng** kết quả đánh giá của K lần train. Từ đó dữ liệu sẽ được đánh giá khách quan và chính xác hơn do được train nhiều lần một cách thông minh hơn trên cùng một tập dữ liệu bé hoặc không cân bằng.\n\nEm sẽ chia training data thành **5 fold** như sau:","metadata":{}},{"cell_type":"code","source":"splits = list(StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=SEED).split(x_train, y_train))","metadata":{"_uuid":"fa55c64890964220ded1762236e091e59e502e53","scrolled":true,"execution":{"iopub.status.busy":"2021-06-10T23:54:00.193206Z","iopub.execute_input":"2021-06-10T23:54:00.193653Z","iopub.status.idle":"2021-06-10T23:54:00.492211Z","shell.execute_reply.started":"2021-06-10T23:54:00.193465Z","shell.execute_reply":"2021-06-10T23:54:00.491326Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"## 3.b Mạng LSTM \n\nMạng bộ nhớ dài-ngắn (*Long Short Term Memory networks*), thường được gọi là LSTM - là một dạng đặc biệt của *RNN* (*Recurrent Neural Network*), nó có khả năng học được các **phụ thuộc xa**. Chúng hoạt động cực kì **hiệu quả** trên nhiều bài toán khác nhau nên dần đã trở nên phổ biến như hiện nay.\n\nLSTM được thiết kế để tránh được vấn đề phụ thuộc xa (long-term dependency). Việc **nhớ** thông tin trong suốt **thời gian dài** là **đặc tính mặc định** của chúng, chứ ta không cần phải huấn luyện nó để có thể nhớ được. Tức là ngay nội tại của nó đã có thể ghi nhớ được mà không cần bất kì can thiệp nào.\n\n<img src=\"https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-chain.png\" width=900>","metadata":{}},{"cell_type":"markdown","source":"Mạng *LSTM* cũng có **kiến trúc** dạng **chuỗi** như *RNN*, tuy nhiên cấu trúc **module** của nó lại có tới **4 tầng** tương tác với nhau một các rất đặc biệt như hình trên. Còn chuỗi module của *RNN* chuẩn được thể hiện ở hình dưới đây: \n\n<img src=\"https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-SimpleRNN.png\" width=900>\n\nChìa khóa của *LSTM* là **trạng thái tế bào** *(cell state)* - chính đường chạy thông ngang phía trên của sơ đồ hình vẽ.\n\nTrạng thái tế bào là một dạng giống như **băng truyền**. Nó chạy **xuyên suốt** tất cả các mắt xích (các nút mạng) và chỉ tương tác tuyến tính đôi chút. Vì vậy mà các thông tin có thể dễ dàng truyền đi thông suốt mà không sợ bị thay đổi.\n\n<img src=\"https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-C-line.png\" width=900>\n\n*LSTM* có khả năng **bỏ đi** hoặc **thêm** vào các **thông tin cần thiết** cho trạng thái tế báo, chúng được **điều chỉnh** cẩn thận bởi các nhóm được gọi là **cổng** (*gate*). Và đó là những khái niệm cốt lõi về *LSTM*. \n\nEm sử dụng 3 layer là **Embed**, **GRU** (*Gated Recurrent Unit*) và **Capsule** **Network** cùng với mạng *LSTM*. Trong đó có 2 khái niệm em chưa đề cập tới đó là: \n* ***GRU***: được sinh ra nhằm giải quyết vấn đề biến mất **gradient** khi sử dụng **RNN**. *GRU* được coi là một biến thể của *LSTM* vì cả hai có nhiều điểm tương đồng. GRU sử dụng **2 vector** cho **update gate** và **reset gate**. 2 vector này quyết định thông tin nào sẽ được truyền cho đầu ra và đặc biệt là nó có thể lưu giữ thông tin từ lâu trước đó. \n\n<img src=\"https://cdn.noron.vn/2018/09/14/e755fbc86c66ce02292382c571e7fdff.jpg?w=600\" width=900>\n\n* ***Capsule Network***: được sinh ra để **cải tiến** mạng **CNN**. Trong mạng này, mỗi *capsule* **đóng gói** tất cả các **thông tin** quan trọng về trạng thái của **feature** trong một vector.\n\n<img src=\"data:image/jpeg;base64,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\">\n\n\n\n\nChúng ta cùng cài đặt qua 3 lớp này:\n\n\nTham khảo tại: https://www.kaggle.com/ziliwang/baseline-pytorch-bilstm","metadata":{}},{"cell_type":"code","source":"import torch as t\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nembedding_dim = 300\nembedding_path = '../save/embedding_matrix.npy'  # or False, not use pre-trained-matrix\nuse_pretrained_embedding = True\n\nhidden_size = 60\ngru_len = hidden_size\n\nRoutings = 4 #5\nNum_capsule = 5\nDim_capsule = 5 #16\ndropout_p = 0.25\nrate_drop_dense = 0.28\nLR = 0.001\nT_epsilon = 1e-7\nnum_classes = 30\n\n\nclass Embed_Layer(nn.Module):\n    def __init__(self, embedding_matrix=None, vocab_size=None, embedding_dim=300):\n        super(Embed_Layer, self).__init__()\n        self.encoder = nn.Embedding(vocab_size + 1, embedding_dim)\n        if use_pretrained_embedding:\n            self.encoder.weight.data.copy_(t.from_numpy(embedding_matrix)) \n\n    def forward(self, x, dropout_p=0.25):\n        return nn.Dropout(p=dropout_p)(self.encoder(x))\n\n\nclass GRU_Layer(nn.Module):\n    def __init__(self):\n        super(GRU_Layer, self).__init__()\n        self.gru = nn.GRU(input_size=300,\n                          hidden_size=gru_len,\n                          bidirectional=True)\n\n\n    def init_weights(self):\n        ih = (param.data for name, param in self.named_parameters() if 'weight_ih' in name)\n        hh = (param.data for name, param in self.named_parameters() if 'weight_hh' in name)\n        b = (param.data for name, param in self.named_parameters() if 'bias' in name)\n        for k in ih:\n            nn.init.xavier_uniform_(k)\n        for k in hh:\n            nn.init.orthogonal_(k)\n        for k in b:\n            nn.init.constant_(k, 0)\n\n    def forward(self, x):\n        return self.gru(x)\n\n\n# core caps_layer with squash func\nclass Caps_Layer(nn.Module):\n    def __init__(self, input_dim_capsule=gru_len * 2, num_capsule=Num_capsule, dim_capsule=Dim_capsule, \\\n                 routings=Routings, kernel_size=(9, 1), share_weights=True,\n                 activation='default', **kwargs):\n        super(Caps_Layer, self).__init__(**kwargs)\n\n        self.num_capsule = num_capsule\n        self.dim_capsule = dim_capsule\n        self.routings = routings\n        self.kernel_size = kernel_size  \n        self.share_weights = share_weights\n        if activation == 'default':\n            self.activation = self.squash\n        else:\n            self.activation = nn.ReLU(inplace=True)\n\n        if self.share_weights:\n            self.W = nn.Parameter(\n                nn.init.xavier_normal_(t.empty(1, input_dim_capsule, self.num_capsule * self.dim_capsule)))\n        else:\n            self.W = nn.Parameter(\n                t.randn(BATCH_SIZE, input_dim_capsule, self.num_capsule * self.dim_capsule))  # 64bit-batch_size\n\n    def forward(self, x):\n\n        if self.share_weights:\n            u_hat_vecs = t.matmul(x, self.W)\n        else:\n            print('add later')\n\n        batch_size = x.size(0)\n        input_num_capsule = x.size(1)\n        u_hat_vecs = u_hat_vecs.view((batch_size, input_num_capsule,\n                                      self.num_capsule, self.dim_capsule))\n        u_hat_vecs = u_hat_vecs.permute(0, 2, 1, 3)  # (batch_size,num_capsule,input_num_capsule,dim_capsule)\n        b = t.zeros_like(u_hat_vecs[:, :, :, 0])  # (batch_size,num_capsule,input_num_capsule)\n\n        for i in range(self.routings):\n            b = b.permute(0, 2, 1)\n            c = F.softmax(b, dim=2)\n            c = c.permute(0, 2, 1)\n            b = b.permute(0, 2, 1)\n            outputs = self.activation(t.einsum('bij,bijk->bik', (c, u_hat_vecs)))  # batch matrix multiplication\n            # outputs shape (batch_size, num_capsule, dim_capsule)\n            if i < self.routings - 1:\n                b = t.einsum('bik,bijk->bij', (outputs, u_hat_vecs))  # batch matrix multiplication\n        return outputs  # (batch_size, num_capsule, dim_capsule)\n\n    # text version of squash, slight different from original one\n    def squash(self, x, axis=-1):\n        s_squared_norm = (x ** 2).sum(axis, keepdim=True)\n        scale = t.sqrt(s_squared_norm + T_epsilon)\n        return x / scale\n    \nclass Capsule_Main(nn.Module):\n    def __init__(self, embedding_matrix=None, vocab_size=None):\n        super(Capsule_Main, self).__init__()\n        self.embed_layer = Embed_Layer(embedding_matrix, vocab_size)\n        self.gru_layer = GRU_Layer()\n        self.gru_layer.init_weights()\n        self.caps_layer = Caps_Layer()\n        self.dense_layer = Dense_Layer()\n\n    def forward(self, content):\n        content1 = self.embed_layer(content)\n        content2, _ = self.gru_layer(\n            content1)  #output(seq_len, batch_size, num_directions * hidden_size)\n        content3 = self.caps_layer(content2)\n        output = self.dense_layer(content3)\n        return output\n    \n","metadata":{"_uuid":"8f7e1d15451201efbac2741b03d4b0dfd3b9bfe0","execution":{"iopub.status.busy":"2021-06-10T23:54:00.493588Z","iopub.execute_input":"2021-06-10T23:54:00.494007Z","iopub.status.idle":"2021-06-10T23:54:00.516028Z","shell.execute_reply.started":"2021-06-10T23:54:00.493818Z","shell.execute_reply":"2021-06-10T23:54:00.515154Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"## 3.c CLR - Cyclic Learning Rate\n\n**Learning rate** là một **tham số** để điều chỉnh mức độ **trọng số** của mạng **neural**. Khi sử dụng **gradient descent**, mục tiêu của chúng ta là tìm ra **cực tiểu** của **hàm mất mát** (*loss function*) trong mô hình. Tuy nhiên ta lại có một vấn đề như hình bên dưới: \n\n<img src=\"https://www.jeremyjordan.me/content/images/2018/02/Screen-Shot-2018-02-24-at-11.47.09-AM.png\" width=900>\n\nThật vậy, khi **learning rate thấp**, chúng ta sẽ mất **nhiều thời gian** hơn để tìm ra được cực tiểu của *loss function*. Khi **learning rate quá cao**, tình hình còn trở nên **tồi tệ hơn**. Vì vậy, ta sẽ dùng **Cyclic Learning Rate** để giải quyết vấn đề này.\n\nKhi sử dụng CLR, chúng ta sẽ:\n* Định nghĩa một **minimum learning rate.**\n* Định nghĩa một **maximum learning rate.**\n* Cho phép learning rate **dao động** theo chu kỳ giữa **2 khoảng giới hạn** trên. \n\n<img src=\"https://pyimagesearch.com/wp-content/uploads/2019/07/keras_clr_triangular.png\" width=900>\n\nTham khảo tại: https://www.kaggle.com/dannykliu/lstm-with-attention-clr-in-pytorch\n<!-- \nhttps://www.pyimagesearch.com/2019/07/29/cyclical-learning-rates-with-keras-and-deep-learning/\n\nhttps://www.datacamp.com/community/tutorials/cyclical-learning-neural-nets -->","metadata":{"_uuid":"8098bea0cee9117ff9dc4e11feba53e49b80cb55"}},{"cell_type":"code","source":"class CyclicLR(object):\n    def __init__(self, optimizer, base_lr=1e-3, max_lr=6e-3,\n                 step_size=2000, mode='triangular', gamma=1.,\n                 scale_fn=None, scale_mode='cycle', last_batch_iteration=-1):\n        if not isinstance(optimizer, Optimizer):\n            raise TypeError('{} is not an Optimizer'.format(\n                type(optimizer).__name__))\n        self.optimizer = optimizer\n\n        if isinstance(base_lr, list) or isinstance(base_lr, tuple):\n            if len(base_lr) != len(optimizer.param_groups):\n                raise ValueError(\"expected {} base_lr, got {}\".format(\n                    len(optimizer.param_groups), len(base_lr)))\n            self.base_lrs = list(base_lr)\n        else:\n            self.base_lrs = [base_lr] * len(optimizer.param_groups)\n\n        if isinstance(max_lr, list) or isinstance(max_lr, tuple):\n            if len(max_lr) != len(optimizer.param_groups):\n                raise ValueError(\"expected {} max_lr, got {}\".format(\n                    len(optimizer.param_groups), len(max_lr)))\n            self.max_lrs = list(max_lr)\n        else:\n            self.max_lrs = [max_lr] * len(optimizer.param_groups)\n\n        self.step_size = step_size\n\n        if mode not in ['triangular', 'triangular2', 'exp_range'] \\\n                and scale_fn is None:\n            raise ValueError('mode is invalid and scale_fn is None')\n\n        self.mode = mode\n        self.gamma = gamma\n\n        if scale_fn is None:\n            if self.mode == 'triangular':\n                self.scale_fn = self._triangular_scale_fn\n                self.scale_mode = 'cycle'\n            elif self.mode == 'triangular2':\n                self.scale_fn = self._triangular2_scale_fn\n                self.scale_mode = 'cycle'\n            elif self.mode == 'exp_range':\n                self.scale_fn = self._exp_range_scale_fn\n                self.scale_mode = 'iterations'\n        else:\n            self.scale_fn = scale_fn\n            self.scale_mode = scale_mode\n\n        self.batch_step(last_batch_iteration + 1)\n        self.last_batch_iteration = last_batch_iteration\n\n    def batch_step(self, batch_iteration=None):\n        if batch_iteration is None:\n            batch_iteration = self.last_batch_iteration + 1\n        self.last_batch_iteration = batch_iteration\n        for param_group, lr in zip(self.optimizer.param_groups, self.get_lr()):\n            param_group['lr'] = lr\n\n    def _triangular_scale_fn(self, x):\n        return 1.\n\n    def _triangular2_scale_fn(self, x):\n        return 1 / (2. ** (x - 1))\n\n    def _exp_range_scale_fn(self, x):\n        return self.gamma**(x)\n\n    def get_lr(self):\n        step_size = float(self.step_size)\n        cycle = np.floor(1 + self.last_batch_iteration / (2 * step_size))\n        x = np.abs(self.last_batch_iteration / step_size - 2 * cycle + 1)\n\n        lrs = []\n        param_lrs = zip(self.optimizer.param_groups, self.base_lrs, self.max_lrs)\n        for param_group, base_lr, max_lr in param_lrs:\n            base_height = (max_lr - base_lr) * np.maximum(0, (1 - x))\n            if self.scale_mode == 'cycle':\n                lr = base_lr + base_height * self.scale_fn(cycle)\n            else:\n                lr = base_lr + base_height * self.scale_fn(self.last_batch_iteration)\n            lrs.append(lr)\n        return lrs\n","metadata":{"_uuid":"9d531a7454923f90d0e7443b1ed1373d008c2e88","scrolled":true,"execution":{"iopub.status.busy":"2021-06-10T23:54:00.517211Z","iopub.execute_input":"2021-06-10T23:54:00.517817Z","iopub.status.idle":"2021-06-10T23:54:00.534657Z","shell.execute_reply.started":"2021-06-10T23:54:00.517692Z","shell.execute_reply":"2021-06-10T23:54:00.533691Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"## 3.d Attention","metadata":{}},{"cell_type":"markdown","source":"<!-- https://machinelearningmastery.com/attention-long-short-term-memory-recurrent-neural-networks/ -->\n\nNhư đã đề cập ở trên, em cũng sẽ sử dụng **attention** vào trong mô hình. *Attention* hiện đang nhận được rất nhiều sự quan tâm từ cộng đồng *Machine Learning*, *Deep Learning* trong thời gian gần đây. Trong các bài toán làm việc với văn bản như dự án này, *attention* luôn được đánh giá cao khi nó khiến mô hình **tập trung** nhiều hơn vào các **từ khóa chính** hay các **câu** văn mang lại **nhiều thông tin** trong văn bản gốc. Dưới đây là một **ví dụ** làm việc với câu \"Germany emerge victorious in 2-0 with against Argentina on Sartuday..\n\n<img src=\"https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/09/Pointer-generator-model-for-Text-Summarization.png\">\n\nChúng ta cùng cài đặt attention và mô hình như dưới đây:","metadata":{}},{"cell_type":"code","source":"class Attention(nn.Module):\n    def __init__(self, feature_dim, step_dim, bias=True, **kwargs):\n        super(Attention, self).__init__(**kwargs)\n        \n        self.supports_masking = True\n\n        self.bias = bias\n        self.feature_dim = feature_dim\n        self.step_dim = step_dim\n        self.features_dim = 0\n        \n        weight = torch.zeros(feature_dim, 1)\n        nn.init.xavier_uniform_(weight)\n        self.weight = nn.Parameter(weight)\n        \n        if bias:\n            self.b = nn.Parameter(torch.zeros(step_dim))\n        \n    def forward(self, x, mask=None):\n        feature_dim = self.feature_dim\n        step_dim = self.step_dim\n\n        eij = torch.mm(\n            x.contiguous().view(-1, feature_dim), \n            self.weight\n        ).view(-1, step_dim)\n        \n        if self.bias:\n            eij = eij + self.b\n            \n        eij = torch.tanh(eij)\n        a = torch.exp(eij)\n        \n        if mask is not None:\n            a = a * mask\n\n        a = a / torch.sum(a, 1, keepdim=True) + 1e-10\n\n        weighted_input = x * torch.unsqueeze(a, -1)\n        return torch.sum(weighted_input, 1)\n    \nclass NeuralNet(nn.Module):\n    def __init__(self):\n        super(NeuralNet, self).__init__()\n        \n        fc_layer = 16\n        fc_layer1 = 16\n\n        self.embedding = nn.Embedding(max_features, embed_size)\n        self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype=torch.float32))\n        self.embedding.weight.requires_grad = False\n        \n        self.embedding_dropout = nn.Dropout2d(0.1)\n        self.lstm = nn.LSTM(embed_size, hidden_size, bidirectional=True, batch_first=True)\n        self.gru = nn.GRU(hidden_size * 2, hidden_size, bidirectional=True, batch_first=True)\n\n        self.lstm2 = nn.LSTM(hidden_size * 2, hidden_size, bidirectional=True, batch_first=True)\n\n        self.lstm_attention = Attention(hidden_size * 2, maxlen)\n        self.gru_attention = Attention(hidden_size * 2, maxlen)\n        self.bn = nn.BatchNorm1d(16, momentum=0.5)\n        self.linear = nn.Linear(hidden_size*8+3, fc_layer1) #643:80 - 483:60 - 323:40\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(0.1)\n        self.fc = nn.Linear(fc_layer**2,fc_layer)\n        self.out = nn.Linear(fc_layer, 1)\n        self.lincaps = nn.Linear(Num_capsule * Dim_capsule, 1)\n        self.caps_layer = Caps_Layer()\n    \n    def forward(self, x):\n        \n#         Capsule(num_capsule=10, dim_capsule=10, routings=4, share_weights=True)(x)\n\n        h_embedding = self.embedding(x[0])\n        h_embedding = torch.squeeze(\n            self.embedding_dropout(torch.unsqueeze(h_embedding, 0)))\n        \n        h_lstm, _ = self.lstm(h_embedding)\n        h_gru, _ = self.gru(h_lstm)\n\n        ##Capsule Layer        \n        content3 = self.caps_layer(h_gru)\n        content3 = self.dropout(content3)\n        batch_size = content3.size(0)\n        content3 = content3.view(batch_size, -1)\n        content3 = self.relu(self.lincaps(content3))\n\n        ##Attention Layer\n        h_lstm_atten = self.lstm_attention(h_lstm)\n        h_gru_atten = self.gru_attention(h_gru)\n        \n        # global average pooling\n        avg_pool = torch.mean(h_gru, 1)\n        # global max pooling\n        max_pool, _ = torch.max(h_gru, 1)\n        \n        f = torch.tensor(x[1], dtype=torch.float).cuda()\n\n                #[512,160]\n        conc = torch.cat((h_lstm_atten, h_gru_atten,content3, avg_pool, max_pool,f), 1)\n        conc = self.relu(self.linear(conc))\n        conc = self.bn(conc)\n        conc = self.dropout(conc)\n\n        out = self.out(conc)\n        \n        return out","metadata":{"_uuid":"170b27f66c7e546d8e84c79357d40f86c6b1ec42","scrolled":true,"execution":{"iopub.status.busy":"2021-06-10T23:54:00.536100Z","iopub.execute_input":"2021-06-10T23:54:00.536602Z","iopub.status.idle":"2021-06-10T23:54:00.555974Z","shell.execute_reply.started":"2021-06-10T23:54:00.536335Z","shell.execute_reply":"2021-06-10T23:54:00.555217Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"# 4. Huấn luyện mô hình\n## 4.a Huấn luyện và dự đoán\nTham khảo tại: https://www.kaggle.com/hengzheng/pytorch-starter","metadata":{"_uuid":"e4e47597cde552a41cdd8ec2531aa6a861e491ae"}},{"cell_type":"markdown","source":"Đầu tiên em **khởi tạo** các biến, mảng và **load** dữ liệu cần thiết cho việc *train* và *predict*.","metadata":{}},{"cell_type":"code","source":"def sigmoid(x):\n    return 1 / (1 + np.exp(-x))\n\n# matrix for the out-of-fold predictions\ntrain_preds = np.zeros((len(x_train)))\n# matrix for the predictions on the test set\ntest_preds = np.zeros((len(df_test)))\n\n# always call this before training for deterministic results\nseed_everything()\n\n# x_test_cuda_f = torch.tensor(x_test_f, dtype=torch.long).cuda()\n# test_f = torch.utils.data.TensorDataset(x_test_cuda_f)\n# test_loader_f = torch.utils.data.DataLoader(test_f, batch_size=batch_size, shuffle=False)\n\n\nx_test_cuda = torch.tensor(x_test, dtype=torch.long).cuda()\ntest = torch.utils.data.TensorDataset(x_test_cuda)\ntest_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False)\n\navg_losses_f = []\navg_val_losses_f = []","metadata":{"_uuid":"0c6339acdc14e6688ed47e9f439e81cd7cfca57f","execution":{"iopub.status.busy":"2021-06-10T23:54:00.557469Z","iopub.execute_input":"2021-06-10T23:54:00.558085Z","iopub.status.idle":"2021-06-10T23:54:04.157440Z","shell.execute_reply.started":"2021-06-10T23:54:00.557926Z","shell.execute_reply":"2021-06-10T23:54:04.155707Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"class MyDataset(Dataset):\n    def __init__(self,dataset):\n        self.dataset = dataset\n\n    def __getitem__(self, index):\n        data, target = self.dataset[index]\n\n        return data, target, index\n    def __len__(self):\n        return len(self.dataset)","metadata":{"_uuid":"704fcb82f5f25d6349a487409f519384df352375","execution":{"iopub.status.busy":"2021-06-10T23:54:04.159310Z","iopub.execute_input":"2021-06-10T23:54:04.159649Z","iopub.status.idle":"2021-06-10T23:54:04.172418Z","shell.execute_reply.started":"2021-06-10T23:54:04.159594Z","shell.execute_reply":"2021-06-10T23:54:04.170223Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"Vì dữ liệu của chúng ta khá lớn nên để tránh bị underfitting khi cho hết dữ liệu vào trong một lần train, em sẽ chia dữ liệu thành một số epoch. Và chắc số epoch cũng không đủ lớn để model bị overfitting. \n\nEm sẽ *train* tập dữ liệu với **5 Fold** (K-Fold Cross Validation), mỗi Fold lại chia thành **5 epoch** với **batch size** là **512** \n\n<img src=\"https://scontent-hkg4-1.xx.fbcdn.net/v/t1.6435-9/74804493_436417456985391_5231059713130496_n.png?_nc_cat=106&ccb=1-3&_nc_sid=730e14&_nc_ohc=qp61hNRFutoAX83LKd0&_nc_ht=scontent-hkg4-1.xx&oh=90fa1ebcb492914b444c03f099c3b5ab&oe=60E7C2CD\" width=900>","metadata":{}},{"cell_type":"code","source":"for i, (train_idx, valid_idx) in enumerate(splits):    \n    # split data in train / validation according to the KFold indeces\n    # also, convert them to a torch tensor and store them on the GPU (done with .cuda())\n    x_train = np.array(x_train)\n    y_train = np.array(y_train)\n    features = np.array(features)\n\n    x_train_fold = torch.tensor(x_train[train_idx.astype(int)], dtype=torch.long).cuda()\n    y_train_fold = torch.tensor(y_train[train_idx.astype(int), np.newaxis], dtype=torch.float32).cuda()\n    \n    kfold_X_features = features[train_idx.astype(int)]\n    kfold_X_valid_features = features[valid_idx.astype(int)]\n    x_val_fold = torch.tensor(x_train[valid_idx.astype(int)], dtype=torch.long).cuda()\n    y_val_fold = torch.tensor(y_train[valid_idx.astype(int), np.newaxis], dtype=torch.float32).cuda()\n    \n    model = NeuralNet()\n\n    # make sure everything in the model is running on the GPU\n    model.cuda()\n\n    # define binary cross entropy loss\n    # note that the model returns logit to take advantage of the log-sum-exp trick \n    # for numerical stability in the loss\n    loss_fn = torch.nn.BCEWithLogitsLoss(reduction='sum')\n\n    step_size = 300\n    base_lr, max_lr = 0.001, 0.003   \n    optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), \n                             lr=max_lr)\n    \n    ################################################################################################\n    scheduler = CyclicLR(optimizer, base_lr=base_lr, max_lr=max_lr,\n               step_size=step_size, mode='exp_range',\n               gamma=0.99994)\n    ###############################################################################################\n\n    train = torch.utils.data.TensorDataset(x_train_fold, y_train_fold)\n    valid = torch.utils.data.TensorDataset(x_val_fold, y_val_fold)\n    \n    train = MyDataset(train)\n    valid = MyDataset(valid)\n\n    ##No need to shuffle the data again here. Shuffling happens when splitting for kfolds.\n    train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n    \n    valid_loader = torch.utils.data.DataLoader(valid, batch_size=batch_size, shuffle=False)\n\n    print(f'Fold {i + 1}')\n    for epoch in range(n_epochs):\n        # set train mode of the model. This enables operations which are only applied during training like dropout\n        start_time = time.time()\n        model.train()\n\n        avg_loss = 0.  \n        for i, (x_batch, y_batch, index) in enumerate(train_loader):\n            # Forward pass: compute predicted y by passing x to the model.\n            ################################################################################################            \n            f = kfold_X_features[index]\n            y_pred = model([x_batch,f])\n            ################################################################################################\n\n            ################################################################################################\n\n            if scheduler:\n                scheduler.batch_step()\n            ################################################################################################\n\n\n            # Compute and print loss.\n            loss = loss_fn(y_pred, y_batch)\n\n            # Before the backward pass, use the optimizer object to zero all of the\n            # gradients for the Tensors it will update (which are the learnable weights\n            # of the model)\n            optimizer.zero_grad()\n\n            # Backward pass: compute gradient of the loss with respect to model parameters\n            loss.backward()\n\n            # Calling the step function on an Optimizer makes an update to its parameters\n            optimizer.step()\n            avg_loss += loss.item() / len(train_loader)\n            \n        # set evaluation mode of the model. This disabled operations which are only applied during training like dropout\n        model.eval()\n        \n        # predict all the samples in y_val_fold batch per batch\n        valid_preds_fold = np.zeros((x_val_fold.size(0)))\n        test_preds_fold = np.zeros((len(df_test)))\n        \n        avg_val_loss = 0.\n        for i, (x_batch, y_batch, index) in enumerate(valid_loader):\n            f = kfold_X_valid_features[index]\n            y_pred = model([x_batch,f]).detach()\n            \n            avg_val_loss += loss_fn(y_pred, y_batch).item() / len(valid_loader)\n            valid_preds_fold[i * batch_size:(i+1) * batch_size] = sigmoid(y_pred.cpu().numpy())[:, 0]\n        \n        elapsed_time = time.time() - start_time \n        print('Epoch {}/{} \\t loss={:.4f} \\t val_loss={:.4f} \\t time={:.2f}s'.format(\n            epoch + 1, n_epochs, avg_loss, avg_val_loss, elapsed_time))\n    avg_losses_f.append(avg_loss)\n    avg_val_losses_f.append(avg_val_loss) \n    # predict all samples in the test set batch per batch\n    for i, (x_batch,) in enumerate(test_loader):\n        f = test_features[i * batch_size:(i+1) * batch_size]\n        y_pred = model([x_batch,f]).detach()\n\n        test_preds_fold[i * batch_size:(i+1) * batch_size] = sigmoid(y_pred.cpu().numpy())[:, 0]\n        \n    train_preds[valid_idx] = valid_preds_fold\n    test_preds += test_preds_fold / len(splits)\n\nprint('All \\t loss={:.4f} \\t val_loss={:.4f} \\t '.format(np.average(avg_losses_f),np.average(avg_val_losses_f)))\n\n# x_train, x_test_f, y_train, y_test_f","metadata":{"_uuid":"2cfdd46b117a11af54ed01f1f9511782e50a00fa","scrolled":true,"execution":{"iopub.status.busy":"2021-06-10T23:54:04.173825Z","iopub.execute_input":"2021-06-10T23:54:04.174259Z","iopub.status.idle":"2021-06-11T00:32:02.007827Z","shell.execute_reply.started":"2021-06-10T23:54:04.174210Z","shell.execute_reply":"2021-06-11T00:32:02.006999Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Fold 1\nEpoch 1/5 \t loss=76.7224 \t val_loss=53.6525 \t time=88.33s\nEpoch 2/5 \t loss=58.3326 \t val_loss=51.6294 \t time=88.68s\nEpoch 3/5 \t loss=54.8715 \t val_loss=50.7202 \t time=87.93s\nEpoch 4/5 \t loss=52.1723 \t val_loss=50.5017 \t time=88.63s\nEpoch 5/5 \t loss=49.2030 \t val_loss=51.2169 \t time=88.74s\nFold 2\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in exp\n  \n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/5 \t loss=76.1012 \t val_loss=53.2243 \t time=88.56s\nEpoch 2/5 \t loss=59.0356 \t val_loss=51.0379 \t time=88.24s\nEpoch 3/5 \t loss=55.3971 \t val_loss=50.5554 \t time=88.21s\nEpoch 4/5 \t loss=53.0002 \t val_loss=50.1828 \t time=88.51s\nEpoch 5/5 \t loss=49.8056 \t val_loss=51.0404 \t time=88.10s\nFold 3\nEpoch 1/5 \t loss=79.2196 \t val_loss=55.5128 \t time=88.21s\nEpoch 2/5 \t loss=58.7476 \t val_loss=51.1694 \t time=88.31s\nEpoch 3/5 \t loss=55.4084 \t val_loss=50.2648 \t time=88.28s\nEpoch 4/5 \t loss=52.7413 \t val_loss=50.9921 \t time=88.48s\nEpoch 5/5 \t loss=49.6857 \t val_loss=51.6895 \t time=88.59s\nFold 4\nEpoch 1/5 \t loss=81.1969 \t val_loss=53.6181 \t time=88.69s\nEpoch 2/5 \t loss=58.7265 \t val_loss=50.7593 \t time=88.25s\nEpoch 3/5 \t loss=55.5935 \t val_loss=50.5710 \t time=88.33s\nEpoch 4/5 \t loss=53.2091 \t val_loss=51.7064 \t time=88.45s\nEpoch 5/5 \t loss=49.8914 \t val_loss=51.5763 \t time=89.05s\nFold 5\nEpoch 1/5 \t loss=79.5755 \t val_loss=66.1431 \t time=88.88s\nEpoch 2/5 \t loss=58.3035 \t val_loss=57.1988 \t time=88.85s\nEpoch 3/5 \t loss=55.1228 \t val_loss=57.2361 \t time=88.77s\nEpoch 4/5 \t loss=52.3738 \t val_loss=56.0662 \t time=88.88s\nEpoch 5/5 \t loss=49.4270 \t val_loss=51.0255 \t time=88.65s\nAll \t loss=49.6025 \t val_loss=51.3097 \t \n","output_type":"stream"}]},{"cell_type":"markdown","source":"<!-- https://www.phamduytung.com/blog/2018-10-02-understanding-epoch-batchsize-iterations/ -->\nCó thể thấy rằng khi **bắt đầu** vào *Fold* mới, **loss** của các Epoch đầu khá **cao**, khoảng **80** nhưng sẽ **giảm dần** xuống khoảng **dưới 50** với mọi *Fold*. Vậy là mô hình đã hoạt động và có kết quả **tốt** khi được huấn luyện với tập *train*. Thời gian chạy cho một *epoch* cũng khá lâu với **90s**. \n\nTuy nhiên để đánh giá **độ chính xác** của *model*, chúng ta sẽ **không dùng accuracy** như thường lệ. Vì như ở phần 2a (Khảo sát dữ liệu), ta đã nhận định rằng tập dữ liệu bị lệch **(imbalance)** khá nặng nên phải sử dụng **f1_score** để đánh giá độ chính xác của mô hình. **F1_score** là một thang điểm từ 0 đến 1 để đánh giá chất lượng mô hình. Chỉ số **F1_score** càng cao càng tốt, **lý tưởng** nhất là bằng **1** khi *Precision* = *Recall* = 1\n\nSau đây là một số công thức liên quan đến chúng:\n\n<img src=\"https://static.packt-cdn.com/products/9781785282287/graphics/B04223_10_02.jpg\">\n\n\n","metadata":{}},{"cell_type":"markdown","source":"## 4.b Find final Thresshold\nTa cùng **tìm** ***thresshold*** tốt nhất để có được **f1_score tốt nhất** khi *submit* lên *Kaggle*","metadata":{"_uuid":"1d2187d4bbf48350eaf365b6dd8b027d5be69e0c"}},{"cell_type":"code","source":"def bestThresshold(y_train,train_preds):\n    tmp = [0,0,0] # idx, cur, max\n    delta = 0\n    for tmp[0] in tqdm(np.arange(0.1, 0.501, 0.01)):\n        tmp[1] = f1_score(y_train, np.array(train_preds)>tmp[0])\n        if tmp[1] > tmp[2]:\n            delta = tmp[0]\n            tmp[2] = tmp[1]\n    print('best threshold is {:.4f} with F1 score: {:.4f}'.format(delta, tmp[2]))\n    return delta\ndelta = bestThresshold(y_train,train_preds)","metadata":{"_uuid":"dc4a4c681294ba06526fed4e871cfe8639cf25e4","scrolled":true,"execution":{"iopub.status.busy":"2021-06-11T00:32:02.009051Z","iopub.execute_input":"2021-06-11T00:32:02.009503Z","iopub.status.idle":"2021-06-11T00:32:10.189841Z","shell.execute_reply.started":"2021-06-11T00:32:02.009450Z","shell.execute_reply":"2021-06-11T00:32:10.189105Z"},"trusted":true},"execution_count":30,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(IntProgress(value=0, max=41), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"09f2182708d044fb8eb14b034d3d041c"}},"metadata":{}},{"name":"stdout","text":"\nbest threshold is 0.3000 with F1 score: 0.6811\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Vậy *threshold* ta tìm được là **0.3** với f1_score là **0.6811**","metadata":{}},{"cell_type":"code","source":"submission = df_test[['qid']].copy()\nsubmission['prediction'] = (test_preds > delta).astype(int)\nsubmission.to_csv('submission.csv', index=False)","metadata":{"_uuid":"d17dd7b0a92ec98134bf8996fd210edaadf7bed6","scrolled":true,"execution":{"iopub.status.busy":"2021-06-11T00:32:10.191009Z","iopub.execute_input":"2021-06-11T00:32:10.191476Z","iopub.status.idle":"2021-06-11T00:32:11.680946Z","shell.execute_reply.started":"2021-06-11T00:32:10.191404Z","shell.execute_reply":"2021-06-11T00:32:11.680073Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"!head submission.csv","metadata":{"_uuid":"a1a07a65e47b5dcefaac040f3f633dc077e8f61e","scrolled":true,"execution":{"iopub.status.busy":"2021-06-11T00:32:11.684144Z","iopub.execute_input":"2021-06-11T00:32:11.684380Z","iopub.status.idle":"2021-06-11T00:32:12.518235Z","shell.execute_reply.started":"2021-06-11T00:32:11.684334Z","shell.execute_reply":"2021-06-11T00:32:12.517158Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"qid,prediction\n0000163e3ea7c7a74cd7,1\n00002bd4fb5d505b9161,0\n00007756b4a147d2b0b3,0\n000086e4b7e1c7146103,0\n0000c4c3fbe8785a3090,0\n000101884c19f3515c1a,0\n00010f62537781f44a47,0\n00012afbd27452239059,0\n00014894849d00ba98a9,0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Tài liệu tham khảo: \n* https://www.kaggle.com/gmhost/gru-capsule\n* How to: Preprocessing when using embeddings\nhttps://www.kaggle.com/christofhenkel/how-to-preprocessing-when-using-embeddings\n* Improve your Score with some Text Preprocessing\nhttps://www.kaggle.com/theoviel/improve-your-score-with-some-text-preprocessing\n* Simple attention layer taken from https://github.com/mttk/rnn-classifier/blob/master/model.py\n* https://www.kaggle.com/ziliwang/baseline-pytorch-bilstm\n* https://www.kaggle.com/hengzheng/pytorch-starter\n* https://www.kaggle.com/shujian/mix-of-nn-models-based-on-meta-embedding\n* https://www.kaggle.com/sudalairajkumar/a-look-at-different-embeddings\n* https://www.kaggle.com/shujian/single-rnn-with-4-folds-clr","metadata":{"_uuid":"6f5ea96dfcc682c232d6cbb6cebd8b48ecabf8fe"}}]}